{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b237c31",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Credit Card Fraud Detection\n",
    "# Tasks C-1 to C-6\n",
    "# ========================\n",
    "\n",
    "# --- 1. Import Libraries ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Sthepa \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# --- 2. Load Data ---\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv(\"../data/creditcard.csv\")\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "display(df.head())\n",
    "\n",
    "# --- 3. Exploratory Data Analysis (C-1) ---\n",
    "print(\"\\nDataset info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nMissing values per column:\\n\", df.isna().sum().sum())\n",
    "print(\"Duplicates:\", df.duplicated().sum())\n",
    "\n",
    "fraud = df[df[\"Class\"] == 1]\n",
    "valid = df[df[\"Class\"] == 0]\n",
    "print(\"Fraud cases:\", len(fraud))\n",
    "print(\"Valid cases:\", len(valid))\n",
    "print(\"Fraud proportion: {:.4f}%\".format(len(fraud)/len(df)*100))\n",
    "\n",
    "sns.countplot(x=\"Class\", data=df)\n",
    "plt.title(\"Fraud (1) vs Valid (0)\")\n",
    "plt.show()\n",
    "\n",
    "# --- 4. Preprocessing ---\n",
    "# Scale Amount and (optionally) Time\n",
    "scaler = StandardScaler()\n",
    "df[\"Amount_scaled\"] = scaler.fit_transform(df[[\"Amount\"]])\n",
    "if \"Time\" in df.columns:\n",
    "    df[\"Time_scaled\"] = scaler.fit_transform(df[[\"Time\"]])\n",
    "\n",
    "# Features and target\n",
    "features = [c for c in df.columns if c not in [\"Class\", \"Amount\", \"Time\"]]\n",
    "X = df[features]\n",
    "y = df[\"Class\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "print(\"Train size:\", X_train.shape, \"Test size:\", X_test.shape)\n",
    "\n",
    "# --- 5. Baseline Model: Logistic Regression (C-2) ---\n",
    "baseline_lr = LogisticRegression(max_iter=2000)\n",
    "baseline_lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = baseline_lr.predict(X_test)\n",
    "y_prob = baseline_lr.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"\\n=== Baseline Logistic Regression ===\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Valid\",\"Fraud\"], yticklabels=[\"Valid\",\"Fraud\"])\n",
    "plt.title(\"Confusion Matrix - Baseline Logistic Regression\")\n",
    "plt.show()\n",
    "\n",
    "# --- 6. Handle Imbalance with SMOTE (C-3) ---\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"\\nBefore SMOTE:\", np.bincount(y_train))\n",
    "print(\"After SMOTE :\", np.bincount(y_train_sm))\n",
    "\n",
    "lr_sm = LogisticRegression(max_iter=2000)\n",
    "lr_sm.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "y_pred_sm = lr_sm.predict(X_test)\n",
    "y_prob_sm = lr_sm.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"\\n=== Logistic Regression + SMOTE ===\")\n",
    "print(classification_report(y_test, y_pred_sm, digits=4))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob_sm))\n",
    "\n",
    "# --- 7. Advanced Model: Random Forest (C-4) ---\n",
    "rf = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_prob_rf = rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"\\n=== Random Forest + SMOTE ===\")\n",
    "print(classification_report(y_test, y_pred_rf, digits=4))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob_rf))\n",
    "\n",
    "# --- 8. Comparison of Models (C-5) ---\n",
    "def summarize(name, y_true, y_pred, y_prob):\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"roc_auc\": roc_auc_score(y_true, y_prob),\n",
    "        \"report\": classification_report(y_true, y_pred, output_dict=True)\n",
    "    }\n",
    "\n",
    "results = [\n",
    "    summarize(\"Baseline LR\", y_test, y_pred, y_prob),\n",
    "    summarize(\"LR + SMOTE\", y_test, y_pred_sm, y_prob_sm),\n",
    "    summarize(\"RF + SMOTE\", y_test, y_pred_rf, y_prob_rf),\n",
    "]\n",
    "\n",
    "pd.DataFrame([{\n",
    "    \"Model\": r[\"model\"],\n",
    "    \"ROC AUC\": r[\"roc_auc\"],\n",
    "    \"Recall (Fraud)\": r[\"report\"][\"1\"][\"recall\"],\n",
    "    \"Precision (Fraud)\": r[\"report\"][\"1\"][\"precision\"],\n",
    "    \"F1-score (Fraud)\": r[\"report\"][\"1\"][\"f1-score\"]\n",
    "} for r in results])\n",
    "\n",
    "# --- 9. Save Final Model (C-6) ---\n",
    "joblib.dump(rf, \"../models/final_rf.joblib\")\n",
    "joblib.dump(scaler, \"../models/amount_time_scaler.joblib\")\n",
    "print(\"Final Random Forest model saved to ../models/final_rf.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a85d6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
